{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brush_teeth 12\n",
      "Climb_stairs 102\n",
      "Comb_hair 31\n",
      "Descend_stairs 42\n",
      "Drink_glass 100\n",
      "Eat_meat 5\n",
      "Eat_soup 3\n",
      "Getup_bed 101\n",
      "Liedown_bed 28\n",
      "Pour_water 100\n",
      "Sitdown_chair 100\n",
      "Standup_chair 102\n",
      "Use_telephone 13\n",
      "Walk 100\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Read each folder in the ADL dataset and create a dictionary with keys = folder/activity name and values = nested list of\n",
    "# flattened file values. Prints the number of files in each folder after reading the data. This snippet assumes that the current\n",
    "# directory is ADL_Dataset/HMP_Dataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "#os.chdir('ADL_Dataset/HMP_Dataset')\n",
    "folders = [x for x in os.listdir() if x.endswith(('_MODEL','.m','.txt'))==False]\n",
    "all_dict = {}\n",
    "for foldername in folders:\n",
    "    for filename in os.listdir(foldername):\n",
    "        with open(foldername+'/'+filename,'r') as f:\n",
    "            if foldername not in all_dict.keys():\n",
    "                all_dict[foldername] = []\n",
    "                all_dict[foldername].append(np.loadtxt(f).flatten().tolist())\n",
    "            else:\n",
    "                all_dict[foldername].append(np.loadtxt(f).flatten().tolist())\n",
    "for key,val in all_dict.items():\n",
    "    print(key, len(val))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Split the all_dict data into two dictionaries - test and train. The split is made in 80:20 ratio; separately for each category.\n",
    "\n",
    "import random\n",
    "import math\n",
    "test,train = {},{}\n",
    "for key,value in all_dict.items():\n",
    "    random.shuffle(value)\n",
    "    testcount = math.ceil(.2*len(value))\n",
    "    test[key] = value[:testcount]\n",
    "    train[key] = value[testcount:]\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a signal and divides into segments of size seg_size (each segment is a vector of length seg_size*3 since the \n",
    "# observations are in 3 dimensions)\n",
    "\n",
    "def split_signal(signal,seg_size):\n",
    "    signal_segs = []\n",
    "    start = 0\n",
    "    end = start + (seg_size*3)\n",
    "    while end <= len(signal):\n",
    "        signal_segs.append(signal[start:end])\n",
    "        start = end\n",
    "        end = start + (seg_size*3)\n",
    "    return signal_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of segments for all training signals and cluster the segments using k-means.\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def build_dict(k,seg_size,train):\n",
    "    seg_arr = []\n",
    "    for key,value in train.items():\n",
    "        for signal in value:\n",
    "            signal_segs = split_signal(signal,seg_size)\n",
    "            seg_arr.extend(signal_segs)\n",
    "    return KMeans(n_clusters=k).fit(seg_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector quantize each signal to obtain k length vectors. Accepts a dictionary (train/test) and kmeans object. Returns two lists-\n",
    "# list of vectors and list of their true labels.\n",
    "# Referred https://piazza.com/class/jchzguhsowz6n9?cid=781 for bincount usage\n",
    "\n",
    "def vecquantize(data, kmeans):\n",
    "    vectors = []\n",
    "    labels = []\n",
    "    for key,value in data.items():\n",
    "        for signal in value:\n",
    "            signal_segs = split_signal(signal,seg_size)\n",
    "            cluster_ids = kmeans.predict(signal_segs)\n",
    "            vector = np.bincount(cluster_ids,minlength=k)\n",
    "            vectors.append(vector)\n",
    "            labels.append(key)\n",
    "    return vectors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function classify_train trains a classifier using Random Forest Classifier\n",
    "# Function classify_measure predicts the labels for input vectors and computes the error rate and confusion matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def classify_train(vectors,labels):\n",
    "    random_forest_classifier = RandomForestClassifier(n_estimators=50,n_jobs=-1)\n",
    "    return random_forest_classifier.fit(vectors, labels)\n",
    "    \n",
    "def classify_measure(rfc, vectors, true_labels):\n",
    "    pred_labels = rfc.predict(vectors)\n",
    "    error_rate = 1 - rfc.score(vectors, true_labels)\n",
    "    print(error_rate)\n",
    "    print(confusion_matrix(true_labels,pred_labels,labels=None))\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.202312138728\n",
      "[[ 2  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0 19  0  0  0  0  0  0  0  0  1  0  0  1]\n",
      " [ 0  0  6  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  8  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 18  0  0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 15  0  2  0  4  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  3  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  1 16  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  5 16  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  2  0  0 17]]\n",
      "0.306358381503\n",
      "[[ 2  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 19  0  0  0  0  0  0  0  0  0  1  0  1]\n",
      " [ 0  0  4  0  0  0  0  0  0  1  1  1  0  0]\n",
      " [ 0  1  0  8  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 19  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 12  0  3  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  2  3  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  3  0  1  8  8  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  8 12  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  4  0  0  0  0  0  0  0  0  1  0  0 15]]\n",
      "0.294797687861\n",
      "[[ 2  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 17  0  0  0  0  0  1  0  0  1  0  0  2]\n",
      " [ 0  0  5  0  0  0  0  0  0  1  1  0  0  0]\n",
      " [ 0  1  0  8  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 19  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  9  0  2  3  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  3  1  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 19  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  2  0  0 12  5  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  5 14  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  3  0  0  0  0  0  0  0  0  1  0  0 16]]\n",
      "0.242774566474\n",
      "[[ 1  0  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  6  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  7  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0 18  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  3  0  0 14  0  1  0  3  0  0]\n",
      " [ 0  0  1  0  0  0  0  1  0  2  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 19  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0 12  5  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  3 18  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  4  0  0  0  0  0  0  0  0  1  0  0 15]]\n",
      "0.277456647399\n",
      "[[ 2  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 19  0  0  0  0  0  1  0  0  0  0  0  1]\n",
      " [ 0  0  6  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  0  8  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 19  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  1  2  0  0  9  0  3  3  2  0  0]\n",
      " [ 0  0  0  1  0  0  0  1  0  1  3  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0 15  3  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  2  7 11  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  5  0  0  0  0  0  0  0  0  1  0  0 14]]\n",
      "0.248554913295\n",
      "[[ 1  0  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  1  0  1  0  0]\n",
      " [ 0  2  0  7  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 19  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0 13  0  1  2  3  0  0]\n",
      " [ 0  0  0  0  0  0  0  3  0  1  2  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0 19  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0 16  3  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  8 12  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  2  0  0  1  0  0  0  0  0  0  0  0 17]]\n",
      "0.242774566474\n",
      "[[ 3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  1  1  0  0  0]\n",
      " [ 0  1  0  7  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0 19  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  1  0  0  0 13  0  2  0  4  0  0]\n",
      " [ 0  0  1  0  0  0  0  2  0  0  3  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0 19  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  1 13  5  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  7 14  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  1  0  0 17]]\n",
      "0.260115606936\n",
      "[[ 3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 18  0  0  0  0  0  1  0  0  0  0  0  2]\n",
      " [ 0  0  5  0  0  0  0  0  0  1  1  0  0  0]\n",
      " [ 0  1  0  8  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 19  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  1  0  0 11  0  2  3  3  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  2  2  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  1 12  5  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  6 15  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  3  0  0  0  0  0  0  0  0  1  0  0 16]]\n",
      "0.265895953757\n",
      "[[ 1  0  0  0  1  0  0  0  0  0  1  0  0  0]\n",
      " [ 0 18  0  0  0  0  0  0  0  0  1  0  0  2]\n",
      " [ 0  0  6  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  2  0  7  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 19  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  2  0  0  1  0  0 11  0  2  0  5  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  2  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1 11  8  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  5 16  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  1  0 17]]\n",
      "0.271676300578\n",
      "[[ 2  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  6  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  8  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 19  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 13  0  2  1  4  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  2  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 19  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0 14  5  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  8 12  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  6  0  0  0  0  0  0  0  0  1  0  0 13]]\n",
      "average error rate  0.261271676301\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# For a given set of test and train data, quantize the data to obtain vectors, train the classifier using training vectors and\n",
    "# compute the average error rate (from 10 runs).  \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "error_rates = []\n",
    "error_rate_sum = 0\n",
    "# 1. seg_list = [16,25,32,50]                              # Uncomment to run for segment sizes 16,25,32 and 50\n",
    "seg_list = [16]                                            # comment if the above line is uncommented\n",
    "# 2. k_list = [100,200,400,600,800,1000]                   # Uncomment to run for k = 100,200,400,600,800,1000    \n",
    "k_list = [600]                                             # Comment if the above line is uncommented  \n",
    "for i in range(0,10):\n",
    "    for segment_size in seg_list:\n",
    "        for k in k_list:\n",
    "            kmeans = build_dict(k=k,seg_size=segment_size,train=train)\n",
    "            train_vecs, train_labels = vecquantize(train,kmeans)\n",
    "            test_vecs, test_labels = vecquantize(test,kmeans)\n",
    "            rfc = classify_train(train_vecs,train_labels)\n",
    "            #error_rates.append(classify_measure(rfc,test_vecs,test_labels))\n",
    "            error_rate = classify_measure(rfc,test_vecs,test_labels)\n",
    "            error_rate_sum += error_rate\n",
    "print('average error rate ',error_rate_sum/10)\n",
    "\n",
    "# The below code creates a plot of error rates against segment sizes and number of clusters\n",
    "\n",
    "#fig1 = plt.figure()\n",
    "#plt.plot(seg_list,error_rates)\n",
    "#plt.xlabel('Segment Size')\n",
    "#plt.ylabel('Error Rate')\n",
    "#plt.xticks(seg_list)\n",
    "#plt.yticks(error_rates)\n",
    "#plt.show()\n",
    "#fig.savefig('Errorrate_seg.png')\n",
    "#fig2 = plt.figure()\n",
    "#plt.plot(k_list,error_rates)\n",
    "#plt.xlabel('K')\n",
    "#plt.ylabel('Error Rate')\n",
    "#plt.xticks(k_list)\n",
    "#plt.yticks(error_rates)\n",
    "#plt.show()\n",
    "#fig.savefig('Errorrate_k.png')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
